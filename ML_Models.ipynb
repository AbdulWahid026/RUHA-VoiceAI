{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3134b3b",
   "metadata": {},
   "source": [
    "# Importing Necessary Libiraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc60fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import pydub\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f17e44",
   "metadata": {},
   "source": [
    "# Slash Character "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb8369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "character='\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1fe67d",
   "metadata": {},
   "source": [
    "# Extracting the required folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ab10951",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=r\"C:\\Users\\HP\\Downloads\"\n",
    "\n",
    "os.chdir(directory)\n",
    "\n",
    "with ZipFile('New DataSet.zip', 'r') as obj:\n",
    "    obj.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3bc70",
   "metadata": {},
   "source": [
    "# Changing into Working Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274c7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir=r\"C:\\Users\\HP\\Downloads\\New DataSet\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831067f",
   "metadata": {},
   "source": [
    "# Code for extraction of Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b62af3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp=working_dir\n",
    "temp+=character\n",
    "files = os.listdir()\n",
    "file_name=[]\n",
    "label=[]\n",
    "feature=[]\n",
    "count=-1\n",
    "mfcc_feature=[]\n",
    "for i in files:\n",
    "    count+=1\n",
    "    os.chdir(temp+i)\n",
    "    for j in os.listdir():\n",
    "        temp1 , temp2 = librosa.load(j)\n",
    "        f= librosa.feature.mfcc(y = temp1, sr = temp2)\n",
    "        feature.append(f)\n",
    "        mfcc_feature.append(np.mean(f.T,axis=0))\n",
    "        label.append(count)\n",
    "        file_name.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c3306",
   "metadata": {},
   "source": [
    "# Code for Flatten and padding of MFCC Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "580f654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[]\n",
    "maximum=0\n",
    "for i in range(0,len(mfcc_feature)):\n",
    "    temp.append(np.array(mfcc_feature[i]).flatten())\n",
    "    if temp[i].shape[0]>maximum:\n",
    "        maximum=temp[i].shape[0]\n",
    "\n",
    "padded_values=[]\n",
    "for i in range(0,len(temp)):\n",
    "    padded_values.append(np.pad(temp[i],(0,maximum-len(temp[i]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c6378",
   "metadata": {},
   "source": [
    "# Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff30cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"File\"]=file_name\n",
    "df[\"Labels\"]=label\n",
    "df[\"MFCC Mean Features\"]=padded_values\n",
    "\n",
    "df=df.drop(columns=\"File\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61edc1",
   "metadata": {},
   "source": [
    "# Storing into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "280dabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(directory)\n",
    "df.to_csv('Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444557e5",
   "metadata": {},
   "source": [
    "# Extracting the Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d669453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train is  (5067,)\n",
      "Shape of y_train is  (5067,)\n",
      "Shape of x_test is  (563,)\n",
      "Shape of y_test is  (563,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df[\"MFCC Features\"],df[\"Labels\"], test_size=0.1, random_state=51)\n",
    "print('Shape of x_train is ', x_train.shape)\n",
    "print('Shape of y_train is ', y_train.shape)\n",
    "print('Shape of x_test is ', x_test.shape)\n",
    "print('Shape of y_test is ', y_test.shape)\n",
    "x_train=list(x_train)\n",
    "x_test=list(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df8b0bc",
   "metadata": {},
   "source": [
    "# Knn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9853db5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  79.21847246891652\n",
      "\t\t\t\t\tReport \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.69      0.62        42\n",
      "           1       0.85      0.93      0.89       337\n",
      "           2       0.77      0.47      0.58        49\n",
      "           3       0.72      0.60      0.65       135\n",
      "\n",
      "    accuracy                           0.79       563\n",
      "   macro avg       0.73      0.67      0.69       563\n",
      "weighted avg       0.79      0.79      0.78       563\n",
      "\n",
      "F1 Score :  68.64614384626745\n",
      "Precision:  72.50866898309795\n",
      "\t\t\tConfusion Matrix  \n",
      " [[ 29   9   0   4]\n",
      " [  4 313   2  18]\n",
      " [  4  12  23  10]\n",
      " [ 14  35   5  81]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, weights='uniform',algorithm='auto',leaf_size=30,p=1,metric='minkowski',metric_params=None,n_jobs=None)\n",
    "knn.fit(x_train, y_train)\n",
    "prediction= knn.predict(x_test)\n",
    "knn.score(x_test,y_test)\n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,prediction)*100)  \n",
    "print(\"\\t\\t\\t\\t\\tReport \\n \", classification_report(y_test, prediction))\n",
    "print(\"F1 Score : \", f1_score(y_test, prediction, average = 'macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, prediction,average = 'macro')*100)\n",
    "print(\"\\t\\t\\tConfusion Matrix  \\n\", confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b1c10",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe22e6e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  63.232682060390765\n",
      "\t\t\t\t\tReport \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.50      0.39        42\n",
      "           1       0.79      0.75      0.77       337\n",
      "           2       0.27      0.29      0.28        49\n",
      "           3       0.54      0.51      0.53       135\n",
      "\n",
      "    accuracy                           0.63       563\n",
      "   macro avg       0.48      0.51      0.49       563\n",
      "weighted avg       0.65      0.63      0.64       563\n",
      "\n",
      "F1 Score :  49.09747822669067\n",
      "Precision:  48.149184018879446\n",
      "\t\t\tConfusion Matrix  \n",
      " [[ 21  12   2   7]\n",
      " [ 24 252  23  38]\n",
      " [  4  18  14  13]\n",
      " [ 17  37  12  69]]\n"
     ]
    }
   ],
   "source": [
    "tr = tree.DecisionTreeClassifier(criterion='gini',splitter='best',max_depth=None,min_samples_split=2,min_samples_leaf=1,min_weight_fraction_leaf=0.0,max_features=None,random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0,)\n",
    "tr = tr.fit(x_train, y_train) \n",
    "prediction = tr.predict(x_test)    \n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,prediction)*100)  \n",
    "print(\"\\t\\t\\t\\t\\tReport \\n \", classification_report(y_test, prediction))\n",
    "print(\"F1 Score : \", f1_score(y_test, prediction, average = 'macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, prediction,average = 'macro')*100)\n",
    "print(\"\\t\\t\\tConfusion Matrix  \\n\", confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85809cb3",
   "metadata": {},
   "source": [
    "# Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13cf4c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  60.03552397868561\n",
      "\t\t\t\t\tReport \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        42\n",
      "           1       0.60      1.00      0.75       337\n",
      "           2       0.00      0.00      0.00        49\n",
      "           3       1.00      0.01      0.01       135\n",
      "\n",
      "    accuracy                           0.60       563\n",
      "   macro avg       0.40      0.25      0.19       563\n",
      "weighted avg       0.60      0.60      0.45       563\n",
      "\n",
      "F1 Score :  19.110694889746775\n",
      "Precision:  39.99110320284698\n",
      "\t\t\tConfusion Matrix  \n",
      " [[  0  42   0   0]\n",
      " [  0 337   0   0]\n",
      " [  0  49   0   0]\n",
      " [  0 134   0   1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "lin_clf.fit(x_train, y_train)\n",
    "prediction = lin_clf.predict(x_test)\n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,prediction)*100)  \n",
    "print(\"\\t\\t\\t\\t\\tReport \\n \", classification_report(y_test, prediction))\n",
    "print(\"F1 Score : \", f1_score(y_test, prediction, average = 'macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, prediction,average = 'macro')*100)\n",
    "print(\"\\t\\t\\tConfusion Matrix  \\n\", confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407815b2",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07dc3a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  74.60035523978685\n",
      "\t\t\t\t\tReport \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.31      0.39        42\n",
      "           1       0.79      0.93      0.85       337\n",
      "           2       0.69      0.18      0.29        49\n",
      "           3       0.67      0.64      0.65       135\n",
      "\n",
      "    accuracy                           0.75       563\n",
      "   macro avg       0.67      0.51      0.55       563\n",
      "weighted avg       0.73      0.75      0.72       563\n",
      "\n",
      "F1 Score :  54.52983693272644\n",
      "Precision:  66.67132867132867\n",
      "\t\t\tConfusion Matrix  \n",
      " [[ 13  15   0  14]\n",
      " [  5 312   3  17]\n",
      " [  2  26   9  12]\n",
      " [  5  43   1  86]]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=600)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,prediction)*100)  \n",
    "print(\"\\t\\t\\t\\t\\tReport \\n \", classification_report(y_test, prediction))\n",
    "print(\"F1 Score : \", f1_score(y_test, prediction, average = 'macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, prediction,average = 'macro')*100)\n",
    "print(\"\\t\\t\\tConfusion Matrix  \\n\", confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39e046",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e60002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  73.17939609236235\n",
      "\t\t\t\t\tReport \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.38      0.46        42\n",
      "           1       0.76      0.93      0.84       337\n",
      "           2       0.53      0.16      0.25        49\n",
      "           3       0.69      0.55      0.61       135\n",
      "\n",
      "    accuracy                           0.73       563\n",
      "   macro avg       0.64      0.51      0.54       563\n",
      "weighted avg       0.71      0.73      0.70       563\n",
      "\n",
      "F1 Score :  53.90116096025186\n",
      "Precision:  63.916031167734\n",
      "\t\t\tConfusion Matrix  \n",
      " [[ 16  15   2   9]\n",
      " [  3 314   4  16]\n",
      " [  2  31   8   8]\n",
      " [  7  53   1  74]]\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "forest = forest.fit(x_train, y_train)\n",
    "prediction = forest.predict(x_test)\n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,prediction)*100)  \n",
    "print(\"\\t\\t\\t\\t\\tReport \\n \", classification_report(y_test, prediction))\n",
    "print(\"F1 Score : \", f1_score(y_test, prediction, average = 'macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, prediction,average = 'macro')*100)\n",
    "print(\"\\t\\t\\tConfusion Matrix  \\n\", confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de7c25",
   "metadata": {},
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459fbf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  75.31083481349911\n",
      "\t\t\t\t\tReport \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.36      0.45        42\n",
      "           1       0.77      0.95      0.85       337\n",
      "           2       0.72      0.27      0.39        49\n",
      "           3       0.73      0.57      0.64       135\n",
      "\n",
      "    accuracy                           0.75       563\n",
      "   macro avg       0.71      0.53      0.58       563\n",
      "weighted avg       0.74      0.75      0.73       563\n",
      "\n",
      "F1 Score :  58.28873447863905\n",
      "Precision:  71.18456196581197\n",
      "\t\t\tConfusion Matrix  \n",
      " [[ 15  18   0   9]\n",
      " [  4 319   1  13]\n",
      " [  3  27  13   6]\n",
      " [  2  52   4  77]]\n"
     ]
    }
   ],
   "source": [
    "extra_tree = ExtraTreesClassifier( n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)\n",
    "extra_tree=extra_tree.fit(x_train, y_train)\n",
    "prediction = extra_tree.predict(x_test)\n",
    "\n",
    "print (\"Accuracy : \", accuracy_score(y_test,prediction)*100)  \n",
    "print(\"\\t\\t\\t\\t\\tReport \\n \", classification_report(y_test, prediction))\n",
    "print(\"F1 Score : \", f1_score(y_test, prediction, average = 'macro')*100)\n",
    "print(\"Precision: \", precision_score(y_test, prediction,average = 'macro')*100)\n",
    "print(\"\\t\\t\\tConfusion Matrix  \\n\", confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773ed7dd",
   "metadata": {},
   "source": [
    "# Storing the pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69f58984",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =r\"C:\\Users\\HP\\Downloads\\PAI Project\\Voice Recorder\"\n",
    "os.chdir(temp)\n",
    "\n",
    "file1=\"ExtraTree_Model.pkl\"\n",
    "pickle.dump(extra_tree, open(file1,'wb'))\n",
    "\n",
    "file2=\"RandomForsest_Model.pkl\"\n",
    "pickle.dump(forest, open(file2,'wb'))\n",
    "\n",
    "file3=\"GradientBoosting_Model.pkl\"\n",
    "pickle.dump(model, open(file3,'wb'))\n",
    "\n",
    "file4=\"Svm_Model.pkl\"\n",
    "pickle.dump(lin_clf, open(file4,'wb'))\n",
    "\n",
    "file5=\"DecisionTree_Model.pkl\"\n",
    "pickle.dump(tr , open(file5,'wb'))\n",
    "\n",
    "file6=\"Knn_Model.pkl\"\n",
    "pickle.dump(knn , open(file6,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
